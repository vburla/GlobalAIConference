{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel='stylesheet' href='../assets/css/main.css'/>\n",
    "\n",
    "[<< back to main index](../README.md) \n",
    "\n",
    "# Lab 2.1 : Up and Running With Spark\n",
    "\n",
    "### Overview\n",
    "We will be running Spark in a single node mode.\n",
    "\n",
    "### Depends On \n",
    "None\n",
    "\n",
    "### Run time\n",
    "20 mins\n",
    "\n",
    "## STEP 0: To Instructor\n",
    "Please go through this lab on 'screen' first.\n",
    "\n",
    "## STEP 1: Login to your Spark node\n",
    "Instructor will provide details\n",
    "\n",
    "\n",
    "## STEP 2: Installing Spark\n",
    "There is no 'install'.  Just unzip/untar and run :-)\n",
    "(copy paste the following commands on terminal,  do not include $ in your commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%bash\n",
    "    $   cd\n",
    "    $   rm -rf  spark   # cleanup existing spark installation (if any)\n",
    "    $   tar xvf   files/spark-2.1.0-bin-hadoop2.7.tgz\n",
    "    $   mv  spark-2.1.0-bin-hadoop2.7    spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have spark installed in  `~/spark`  directory\n",
    "\n",
    "\n",
    "## STEP 3: Running Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "   $   ~/spark/sbin/start-all.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify Spark is running by 'jps' command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "   $  jps\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your output may look like this.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "attributes": {
     "classes": [
      "console"
     ],
     "id": ""
    }
   },
   "source": [
    "```  \n",
    "  30624 Jps\n",
    "  30431 Master\n",
    "  30565 Worker\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you will see **Master** and **Worker**  processes running.\n",
    "(you probably will get different values for process ids - first column )\n",
    "\n",
    "Spark UI will be at port 8080 of the host.\n",
    "In browser go to\n",
    "  http://your_spark_host_address:8080\n",
    "(be sure to use the 'public' ip address)\n",
    "\n",
    "bingo!  Now we have spark running.\n",
    "\n",
    "\n",
    "## STEP 4: Exploring Spark UI\n",
    "You will see a similar screen shot like this\n",
    "\n",
    "<img src=\"../assets/images/1a.png\" style=\"border: 5px solid grey ; max-width:100%;\" /> \n",
    "\n",
    "To explore:\n",
    "* Is Master and Worker running on the same node?\n",
    "\n",
    "* Inspect memory & CPU available for Spark worker\n",
    "\n",
    "* Note the Spark master URI, it will be something like\n",
    "      spark://host_name:7077\n",
    "    We will need this for later labs\n",
    "\n",
    "\n",
    "## STEP 5: Download Spark labs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "    $   cd\n",
    "    $   git clone   git@github.com:elephantscale/spark-labs.git\n",
    "\n",
    "    # for v2 - latest\n",
    "    # $  cd  ~/spark-labs\n",
    "    # $  git checkout master\n",
    "\n",
    "    # for 1.6 (old)\n",
    "    $  cd ~/spark-labs\n",
    "    $  git checkout v1.6\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create a `spark-labs` directory that has all the labs.\n",
    "\n",
    "## Optional 1: Spark VM\n",
    "\n",
    "Here are a virtual machine for you\n",
    "\n",
    "CentOS: https://s3.amazonaws.com/elephantscale-public/vm/CentOS.ova   \n",
    "Ubuntu: https://s3.amazonaws.com/elephantscale-public/vm/Ubuntu.ova\n",
    "\n",
    "\n",
    "They are in the OVA format, useable both in VMWare and VirtualBox. \n",
    "\n",
    "User name: es   \n",
    "Password: student\n",
    "\n",
    "## Optional 2: Running Spark on Windows\n",
    "\n",
    "If one has to do a Windows install, here is the magic\n",
    "\n",
    "http://nishutayaltech.blogspot.com/2015/04/how-to-run-apache-spark-on-windows7-in.html\n",
    "\n",
    "set winutils as described\n",
    "\n",
    "For example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "   \\projects\n",
    "   \\projects\\spark-labs\n",
    "   \\projects\\spark-1.4.1-bin-hadoop2.4\n",
    "   \\projects\\winutils\\bin\\winutils\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System env variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "   HADOOP_HOME=\\projects\\winutils\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this download spark-1.4.1-bin-hadoop2.4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
