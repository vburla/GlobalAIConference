{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel='stylesheet' href='../assets/css/main.css'/>\n",
    "\n",
    "[<< back to main index](../README.md)\n",
    "\n",
    "Lab 4.2 : Spark SQL : SQL\n",
    "================================\n",
    "\n",
    "\n",
    "### Overview\n",
    "Using SQL statements with Spark SQL.   \n",
    "\n",
    "### Depends On \n",
    "None\n",
    "\n",
    "### Run time\n",
    "20-30 mins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: Load Clickstream data\n",
    "\n",
    "**==> Create a dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clickstreamDF = spark.read.json(\"../data/click-stream/clickstream.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==> Register dataframe as a table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clickstreamDF.createOrReplaceTempView(\"clickstream\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: Querying using SQL\n",
    "\n",
    "\n",
    "**==> Select all logs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logs = spark.sql(\"select * from clickstream\")\n",
    "#'logs' is a dataframe\n",
    "logs.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output might be like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "+-------+-----------+----+-----------------+----+----------+-------------+------+\n",
    "| action|   campaign|cost|           domain|  ip|   session|    timestamp|  user|\n",
    "+-------+-----------+----+-----------------+----+----------+-------------+------+\n",
    "|clicked|campaign_19| 118|      youtube.com|ip_4|session_36|1420070400000|user_9|\n",
    "|blocked|campaign_12|   5|     facebook.com|ip_3|session_96|1420070400864|user_5|\n",
    "|clicked| campaign_3|  54|sf.craigslist.org|ip_9|session_61|1420070401728|user_8|\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==> Find records with only clicks**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Find Records with only clicks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==> Count records from each domain, sort the output by most to least**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Try this query here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### STEP 3: Joining Datasets\n",
    "\n",
    "**==> Load `domains` dataset and register it to table `domains`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "domainsDF = spark.read.json(\"../data/click-stream/domain-info.json\")\n",
    "domainsDF.show()\n",
    "domainsDF.createOrReplaceTempView(\"domains\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==> Join `clickstreams` and `domains`**    \n",
    "Hint : Join query syntax for joining two tables A, B\n",
    "spark.sql(\"select A.*, B.* from A  join B  ON (A.x = B.y)\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "sql"
     ],
     "id": ""
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Write sql query for joining clickstreams and domains\n",
    "# spark.sql(\"SELECT ....\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**==> Count traffic per domain category (news, social ..etc)**    \n",
    "Hint : query the joined datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Count traffic per domained category\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### STEP 4: Explore UI\n",
    "(Your DAG visualization may be slightly different from what we show here)\n",
    "\n",
    "<img src=\"../assets/images/5.2c.png\" style=\"border: 5px solid grey; max-width:100%;\"/>\n",
    "\n",
    "<img src=\"../assets/images/5.2d.png\" style=\"border: 5px solid grey; max-width:100%;\"/>\n",
    "\n",
    "<img src=\"../assets/images/5.2e.png\" style=\"border: 5px solid grey; max-width:100%;\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
